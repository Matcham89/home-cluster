---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kagent-llm-usage-dashboard
  namespace: monitoring
  labels:
    grafana_dashboard: "1"
data:
  kagent-llm-usage.json: |-
    {
      "annotations": {
        "list": [
          {
            "builtIn": 1,
            "datasource": {
              "type": "grafana",
              "uid": "-- Grafana --"
            },
            "enable": true,
            "hide": true,
            "iconColor": "rgba(0, 211, 255, 1)",
            "name": "Annotations & Alerts",
            "type": "dashboard"
          }
        ]
      },
      "description": "Monitor kagent LLM usage, token consumption, and estimated costs across agents and models",
      "editable": true,
      "fiscalYearStartMonth": 0,
      "graphTooltip": 0,
      "id": null,
      "links": [],
      "panels": [
        {
          "datasource": {
            "type": "tempo",
            "uid": "tempo"
          },
          "description": "Estimated cost calculated from input and output token usage with model-specific pricing (Anthropic Claude pricing)",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "yellow",
                    "value": 1
                  },
                  {
                    "color": "red",
                    "value": 10
                  }
                ]
              },
              "unit": "currencyUSD"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 6,
            "w": 24,
            "x": 0,
            "y": 0
          },
          "id": 1,
          "options": {
            "colorMode": "background",
            "graphMode": "area",
            "justifyMode": "center",
            "orientation": "auto",
            "percentChangeColorMode": "standard",
            "reduceOptions": {
              "calcs": [
                "sum"
              ],
              "fields": "",
              "values": false
            },
            "showPercentChange": false,
            "textMode": "auto",
            "wideLayout": true
          },
          "pluginVersion": "11.6.3",
          "targets": [
            {
              "datasource": {
                "type": "tempo",
                "uid": "tempo"
              },
              "limit": 20,
              "query": "{ name=\"call_llm\" } | select(span.gen_ai.usage.input_tokens, span.gen_ai.usage.output_tokens, span.gen_ai.request.model)",
              "queryType": "traceqlSearch",
              "refId": "A",
              "tableType": "spans"
            }
          ],
          "title": "Estimated Total Cost",
          "transformations": [
            {
              "id": "extractFields",
              "options": {
                "source": "gen_ai.request.model"
              }
            },
            {
              "id": "calculateField",
              "options": {
                "alias": "input_cost",
                "binary": {
                  "left": "gen_ai.usage.input_tokens",
                  "operator": "*",
                  "right": "0.000003"
                },
                "mode": "binary",
                "replaceFields": false
              }
            },
            {
              "id": "calculateField",
              "options": {
                "alias": "output_cost",
                "binary": {
                  "left": "gen_ai.usage.output_tokens",
                  "operator": "*",
                  "right": "0.000015"
                },
                "mode": "binary",
                "replaceFields": false
              }
            },
            {
              "id": "calculateField",
              "options": {
                "alias": "total_cost",
                "binary": {
                  "left": "input_cost",
                  "operator": "+",
                  "right": "output_cost"
                },
                "mode": "binary",
                "replaceFields": false
              }
            }
          ],
          "type": "stat"
        },
        {
          "datasource": {
            "type": "tempo",
            "uid": "tempo"
          },
          "description": "Total number of input (prompt) tokens processed across all LLM calls",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  }
                ]
              },
              "unit": "short"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 5,
            "w": 8,
            "x": 0,
            "y": 6
          },
          "id": 2,
          "options": {
            "colorMode": "background",
            "graphMode": "area",
            "justifyMode": "center",
            "orientation": "auto",
            "percentChangeColorMode": "standard",
            "reduceOptions": {
              "calcs": [
                "sum"
              ],
              "fields": "/^gen_ai\\.usage\\.input_tokens$/",
              "values": false
            },
            "showPercentChange": false,
            "textMode": "auto",
            "wideLayout": true
          },
          "pluginVersion": "11.6.3",
          "targets": [
            {
              "datasource": {
                "type": "tempo",
                "uid": "tempo"
              },
              "limit": 20,
              "query": "{ name=\"call_llm\" } | select(span.gen_ai.usage.input_tokens)",
              "queryType": "traceqlSearch",
              "refId": "A",
              "tableType": "spans"
            }
          ],
          "title": "Total Input Tokens",
          "type": "stat"
        },
        {
          "datasource": {
            "type": "tempo",
            "uid": "tempo"
          },
          "description": "Total number of output (generated) tokens across all LLM calls",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  }
                ]
              },
              "unit": "short"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 5,
            "w": 8,
            "x": 8,
            "y": 6
          },
          "id": 3,
          "options": {
            "colorMode": "background",
            "graphMode": "area",
            "justifyMode": "center",
            "orientation": "auto",
            "percentChangeColorMode": "standard",
            "reduceOptions": {
              "calcs": [
                "sum"
              ],
              "fields": "/^gen_ai\\.usage\\.output_tokens$/",
              "values": false
            },
            "showPercentChange": false,
            "textMode": "auto",
            "wideLayout": true
          },
          "pluginVersion": "11.6.3",
          "targets": [
            {
              "datasource": {
                "type": "tempo",
                "uid": "tempo"
              },
              "limit": 20,
              "query": "{ name=\"call_llm\" } | select(span.gen_ai.usage.output_tokens)",
              "queryType": "traceqlSearch",
              "refId": "A",
              "tableType": "spans"
            }
          ],
          "title": "Total Output Tokens",
          "type": "stat"
        },
        {
          "datasource": {
            "type": "tempo",
            "uid": "tempo"
          },
          "description": "Total number of LLM API calls made by kagent agents",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  }
                ]
              },
              "unit": "short"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 5,
            "w": 8,
            "x": 16,
            "y": 6
          },
          "id": 4,
          "options": {
            "colorMode": "background",
            "graphMode": "area",
            "justifyMode": "center",
            "orientation": "auto",
            "percentChangeColorMode": "standard",
            "reduceOptions": {
              "calcs": [
                "count"
              ],
              "fields": "",
              "values": false
            },
            "showPercentChange": false,
            "textMode": "auto",
            "wideLayout": true
          },
          "pluginVersion": "11.6.3",
          "targets": [
            {
              "datasource": {
                "type": "tempo",
                "uid": "tempo"
              },
              "limit": 20,
              "query": "{ name=\"call_llm\" }",
              "queryType": "traceqlSearch",
              "refId": "A",
              "tableType": "spans"
            }
          ],
          "title": "Total LLM Calls",
          "type": "stat"
        },
        {
          "datasource": {
            "type": "tempo",
            "uid": "tempo"
          },
          "description": "Token usage breakdown by agent",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisBorderShow": false,
                "axisCenteredZero": false,
                "axisColorMode": "text",
                "axisLabel": "",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "barWidthFactor": 0.6,
                "drawStyle": "bars",
                "fillOpacity": 60,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "insertNulls": false,
                "lineInterpolation": "smooth",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "normal"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  }
                ]
              },
              "unit": "short"
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byRegexp",
                  "options": ".*input.*"
                },
                "properties": [
                  {
                    "id": "color",
                    "value": {
                      "fixedColor": "blue",
                      "mode": "fixed"
                    }
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byRegexp",
                  "options": ".*output.*"
                },
                "properties": [
                  {
                    "id": "color",
                    "value": {
                      "fixedColor": "green",
                      "mode": "fixed"
                    }
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 10,
            "w": 24,
            "x": 0,
            "y": 11
          },
          "id": 5,
          "options": {
            "legend": {
              "calcs": [
                "sum",
                "mean"
              ],
              "displayMode": "table",
              "placement": "right",
              "showLegend": true
            },
            "tooltip": {
              "mode": "multi",
              "sort": "none"
            }
          },
          "pluginVersion": "11.6.3",
          "targets": [
            {
              "datasource": {
                "type": "tempo",
                "uid": "tempo"
              },
              "limit": 20,
              "query": "{ name=\"call_llm\" } | select(span.gen_ai.usage.input_tokens, span.gen_ai.usage.output_tokens, span.gen_ai.agent.name)",
              "queryType": "traceqlSearch",
              "refId": "A",
              "tableType": "spans"
            }
          ],
          "title": "Token Usage by Agent",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "tempo",
            "uid": "tempo"
          },
          "description": "Token usage breakdown by model",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisBorderShow": false,
                "axisCenteredZero": false,
                "axisColorMode": "text",
                "axisLabel": "",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "barWidthFactor": 0.6,
                "drawStyle": "bars",
                "fillOpacity": 60,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "insertNulls": false,
                "lineInterpolation": "smooth",
                "lineWidth": 1,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "normal"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  }
                ]
              },
              "unit": "short"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 10,
            "w": 24,
            "x": 0,
            "y": 21
          },
          "id": 6,
          "options": {
            "legend": {
              "calcs": [
                "sum",
                "mean"
              ],
              "displayMode": "table",
              "placement": "right",
              "showLegend": true
            },
            "tooltip": {
              "mode": "multi",
              "sort": "none"
            }
          },
          "pluginVersion": "11.6.3",
          "targets": [
            {
              "datasource": {
                "type": "tempo",
                "uid": "tempo"
              },
              "limit": 20,
              "query": "{ name=\"call_llm\" } | select(span.gen_ai.usage.input_tokens, span.gen_ai.usage.output_tokens, span.gen_ai.request.model)",
              "queryType": "traceqlSearch",
              "refId": "A",
              "tableType": "spans"
            }
          ],
          "title": "Token Usage by Model",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "tempo",
            "uid": "tempo"
          },
          "description": "Average LLM call latency by agent",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisBorderShow": false,
                "axisCenteredZero": false,
                "axisColorMode": "text",
                "axisLabel": "",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "barWidthFactor": 0.6,
                "drawStyle": "line",
                "fillOpacity": 20,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "insertNulls": false,
                "lineInterpolation": "smooth",
                "lineWidth": 2,
                "pointSize": 5,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  }
                ]
              },
              "unit": "ms"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 10,
            "w": 24,
            "x": 0,
            "y": 31
          },
          "id": 7,
          "options": {
            "legend": {
              "calcs": [
                "mean",
                "max"
              ],
              "displayMode": "table",
              "placement": "right",
              "showLegend": true
            },
            "tooltip": {
              "mode": "multi",
              "sort": "none"
            }
          },
          "pluginVersion": "11.6.3",
          "targets": [
            {
              "datasource": {
                "type": "tempo",
                "uid": "tempo"
              },
              "limit": 20,
              "query": "{ name=\"call_llm\" } | select(span.duration, span.gen_ai.agent.name)",
              "queryType": "traceqlSearch",
              "refId": "A",
              "tableType": "spans"
            }
          ],
          "title": "LLM Call Latency by Agent",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "tempo",
            "uid": "tempo"
          },
          "description": "Detailed table of recent LLM calls with token usage and cost estimates",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": "auto",
                "cellOptions": {
                  "type": "auto"
                },
                "inspect": false
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  }
                ]
              }
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "Estimated Cost"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "currencyUSD"
                  },
                  {
                    "id": "custom.cellOptions",
                    "value": {
                      "type": "color-background"
                    }
                  },
                  {
                    "id": "thresholds",
                    "value": {
                      "mode": "absolute",
                      "steps": [
                        {
                          "color": "green",
                          "value": null
                        },
                        {
                          "color": "yellow",
                          "value": 0.01
                        },
                        {
                          "color": "red",
                          "value": 0.1
                        }
                      ]
                    }
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 12,
            "w": 24,
            "x": 0,
            "y": 41
          },
          "id": 8,
          "options": {
            "cellHeight": "sm",
            "footer": {
              "countRows": false,
              "fields": "",
              "reducer": [
                "sum"
              ],
              "show": false
            },
            "showHeader": true,
            "sortBy": []
          },
          "pluginVersion": "11.6.3",
          "targets": [
            {
              "datasource": {
                "type": "tempo",
                "uid": "tempo"
              },
              "limit": 50,
              "query": "{ name=\"call_llm\" } | select(span.gen_ai.agent.name, span.gen_ai.request.model, span.gen_ai.usage.input_tokens, span.gen_ai.usage.output_tokens, span.duration)",
              "queryType": "traceqlSearch",
              "refId": "A",
              "tableType": "spans"
            }
          ],
          "title": "Recent LLM Calls",
          "transformations": [
            {
              "id": "organize",
              "options": {
                "excludeByName": {},
                "includeByName": {},
                "indexByName": {
                  "duration": 5,
                  "gen_ai.agent.name": 0,
                  "gen_ai.request.model": 1,
                  "gen_ai.usage.input_tokens": 2,
                  "gen_ai.usage.output_tokens": 3,
                  "startTime": 4
                },
                "renameByName": {
                  "duration": "Duration (ms)",
                  "gen_ai.agent.name": "Agent",
                  "gen_ai.request.model": "Model",
                  "gen_ai.usage.input_tokens": "Input Tokens",
                  "gen_ai.usage.output_tokens": "Output Tokens",
                  "startTime": "Time"
                }
              }
            },
            {
              "id": "calculateField",
              "options": {
                "alias": "Total Tokens",
                "binary": {
                  "left": "Input Tokens",
                  "operator": "+",
                  "right": "Output Tokens"
                },
                "mode": "binary",
                "replaceFields": false
              }
            },
            {
              "id": "calculateField",
              "options": {
                "alias": "Estimated Cost",
                "binary": {
                  "left": "Input Tokens",
                  "operator": "*",
                  "right": "0.000003"
                },
                "mode": "binary",
                "replaceFields": false
              }
            },
            {
              "id": "calculateField",
              "options": {
                "alias": "temp_output_cost",
                "binary": {
                  "left": "Output Tokens",
                  "operator": "*",
                  "right": "0.000015"
                },
                "mode": "binary",
                "replaceFields": false
              }
            },
            {
              "id": "calculateField",
              "options": {
                "alias": "Estimated Cost",
                "binary": {
                  "left": "Estimated Cost",
                  "operator": "+",
                  "right": "temp_output_cost"
                },
                "mode": "binary",
                "replaceFields": true
              }
            }
          ],
          "type": "table"
        }
      ],
      "schemaVersion": 41,
      "tags": [
        "kagent",
        "LLM",
        "usage",
        "cost"
      ],
      "templating": {
        "list": []
      },
      "time": {
        "from": "now-24h",
        "to": "now"
      },
      "timepicker": {
        "refresh_intervals": [
          "5m",
          "15m",
          "30m",
          "1h",
          "2h",
          "1d"
        ]
      },
      "timezone": "browser",
      "title": "kagent - LLM Usage & Cost",
      "uid": "kagent-llm-usage",
      "version": 1
    }
