apiVersion: v1
kind: ConfigMap
metadata:
  name: kagent-llm-usage-dashboard
  namespace: monitoring
  labels:
    grafana_dashboard: "1"
data:
  kagent-llm-usage.json: |-
    {
      "annotations": {
        "list": [
          {
            "builtIn": 1,
            "datasource": {
              "type": "grafana",
              "uid": "-- Grafana --"
            },
            "enable": true,
            "hide": true,
            "iconColor": "rgba(0, 211, 255, 1)",
            "name": "Annotations & Alerts",
            "type": "dashboard"
          }
        ]
      },
      "description": "LLM token usage, costs, and performance metrics from kagent traces",
      "editable": true,
      "fiscalYearStartMonth": 0,
      "graphTooltip": 0,
      "id": 17,
      "links": [],
      "panels": [
        {
          "datasource": {
            "type": "tempo",
            "uid": "tempo"
          },
          "description": "Total input tokens across all LLM calls in time range",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": 0
                  },
                  {
                    "color": "yellow",
                    "value": 100000
                  },
                  {
                    "color": "red",
                    "value": 500000
                  }
                ]
              },
              "unit": "none"
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "Input Tokens"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "none"
                  },
                  {
                    "id": "decimals",
                    "value": 0
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 4,
            "w": 12,
            "x": 0,
            "y": 0
          },
          "id": 2,
          "options": {
            "colorMode": "value",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "auto",
            "percentChangeColorMode": "standard",
            "reduceOptions": {
              "calcs": [
                "sum"
              ],
              "fields": "/^Input Tokens$/",
              "values": false
            },
            "showPercentChange": false,
            "textMode": "auto",
            "wideLayout": true
          },
          "pluginVersion": "12.2.1",
          "targets": [
            {
              "datasource": {
                "type": "tempo",
                "uid": "tempo"
              },
              "limit": 100000,
              "query": "{resource.service.name=\"kagent\" && name=\"call_llm\"} | select(span.gen_ai.usage.input_tokens)",
              "queryType": "traceql",
              "refId": "A",
              "tableType": "spans"
            }
          ],
          "title": "Total Input Tokens",
          "transformations": [
            {
              "id": "organize",
              "options": {
                "excludeByName": {
                  "durationMs": true,
                  "spanID": true,
                  "startTimeUnixNano": true,
                  "traceID": true
                },
                "indexByName": {},
                "renameByName": {
                  "gen_ai.usage.input_tokens": "Input Tokens"
                }
              }
            },
            {
              "id": "convertFieldType",
              "options": {
                "conversions": [
                  {
                    "destinationType": "number",
                    "targetField": "Input Tokens"
                  }
                ],
                "fields": {}
              }
            }
          ],
          "type": "stat"
        },
        {
          "datasource": {
            "type": "tempo",
            "uid": "tempo"
          },
          "description": "Total output tokens across all LLM calls in time range",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": 0
                  },
                  {
                    "color": "yellow",
                    "value": 50000
                  },
                  {
                    "color": "red",
                    "value": 200000
                  }
                ]
              },
              "unit": "none"
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "Output Tokens"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "none"
                  },
                  {
                    "id": "decimals",
                    "value": 0
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 4,
            "w": 12,
            "x": 12,
            "y": 0
          },
          "id": 3,
          "options": {
            "colorMode": "value",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "auto",
            "percentChangeColorMode": "standard",
            "reduceOptions": {
              "calcs": [
                "sum"
              ],
              "fields": "/^Output Tokens$/",
              "values": false
            },
            "showPercentChange": false,
            "textMode": "auto",
            "wideLayout": true
          },
          "pluginVersion": "12.2.1",
          "targets": [
            {
              "datasource": {
                "type": "tempo",
                "uid": "tempo"
              },
              "limit": 100000,
              "query": "{resource.service.name=\"kagent\" && name=\"call_llm\"} | select(span.gen_ai.usage.output_tokens)",
              "queryType": "traceql",
              "refId": "A",
              "tableType": "spans"
            }
          ],
          "title": "Total Output Tokens",
          "transformations": [
            {
              "id": "organize",
              "options": {
                "excludeByName": {
                  "durationMs": true,
                  "spanID": true,
                  "startTimeUnixNano": true,
                  "traceID": true
                },
                "indexByName": {},
                "renameByName": {
                  "gen_ai.usage.output_tokens": "Output Tokens"
                }
              }
            },
            {
              "id": "convertFieldType",
              "options": {
                "conversions": [
                  {
                    "destinationType": "number",
                    "targetField": "Output Tokens"
                  }
                ],
                "fields": {}
              }
            }
          ],
          "type": "stat"
        },
        {
          "datasource": {
            "type": "tempo",
            "uid": "tempo"
          },
          "description": "Total input tokens across all LLM calls in time range",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": 0
                  },
                  {
                    "color": "yellow",
                    "value": 100000
                  },
                  {
                    "color": "red",
                    "value": 500000
                  }
                ]
              },
              "unit": "none"
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "Input Tokens"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "none"
                  },
                  {
                    "id": "decimals",
                    "value": 0
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 4,
            "w": 6,
            "x": 0,
            "y": 4
          },
          "id": 15,
          "options": {
            "colorMode": "value",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "auto",
            "percentChangeColorMode": "standard",
            "reduceOptions": {
              "calcs": [
                "sum"
              ],
              "fields": "/^Input Tokens$/",
              "values": false
            },
            "showPercentChange": false,
            "textMode": "auto",
            "wideLayout": true
          },
          "pluginVersion": "12.2.1",
          "targets": [
            {
              "datasource": {
                "type": "tempo",
                "uid": "tempo"
              },
              "limit": 100000,
              "metricsQueryType": "range",
              "query": "{resource.service.name=\"kagent\" && name=\"call_llm\" && span.gen_ai.request.model=~\"gpt.*\"} | select(span.gen_ai.usage.input_tokens)",
              "queryType": "traceql",
              "refId": "A",
              "serviceMapUseNativeHistograms": false,
              "tableType": "spans"
            }
          ],
          "title": "GPT Input Tokens",
          "transformations": [
            {
              "id": "organize",
              "options": {
                "excludeByName": {
                  "durationMs": true,
                  "spanID": true,
                  "startTimeUnixNano": true,
                  "traceID": true
                },
                "indexByName": {},
                "renameByName": {
                  "gen_ai.usage.input_tokens": "Input Tokens"
                }
              }
            },
            {
              "id": "convertFieldType",
              "options": {
                "conversions": [
                  {
                    "destinationType": "number",
                    "targetField": "Input Tokens"
                  }
                ],
                "fields": {}
              }
            }
          ],
          "type": "stat"
        },
        {
          "datasource": {
            "type": "tempo",
            "uid": "tempo"
          },
          "description": "Total output tokens across all LLM calls in time range",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": 0
                  },
                  {
                    "color": "yellow",
                    "value": 50000
                  },
                  {
                    "color": "red",
                    "value": 200000
                  }
                ]
              },
              "unit": "none"
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "Output Tokens"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "none"
                  },
                  {
                    "id": "decimals",
                    "value": 0
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 4,
            "w": 6,
            "x": 6,
            "y": 4
          },
          "id": 17,
          "options": {
            "colorMode": "value",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "auto",
            "percentChangeColorMode": "standard",
            "reduceOptions": {
              "calcs": [
                "sum"
              ],
              "fields": "/^Output Tokens$/",
              "values": false
            },
            "showPercentChange": false,
            "textMode": "auto",
            "wideLayout": true
          },
          "pluginVersion": "12.2.1",
          "targets": [
            {
              "datasource": {
                "type": "tempo",
                "uid": "tempo"
              },
              "limit": 100000,
              "metricsQueryType": "range",
              "query": "{resource.service.name=\"kagent\" && name=\"call_llm\" && span.gen_ai.request.model=~\"gpt.*\"} | select(span.gen_ai.usage.output_tokens)",
              "queryType": "traceql",
              "refId": "A",
              "serviceMapUseNativeHistograms": false,
              "tableType": "spans"
            }
          ],
          "title": "GPT Output Tokens",
          "transformations": [
            {
              "id": "organize",
              "options": {
                "excludeByName": {
                  "durationMs": true,
                  "spanID": true,
                  "startTimeUnixNano": true,
                  "traceID": true
                },
                "indexByName": {},
                "renameByName": {
                  "gen_ai.usage.output_tokens": "Output Tokens"
                }
              }
            },
            {
              "id": "convertFieldType",
              "options": {
                "conversions": [
                  {
                    "destinationType": "number",
                    "targetField": "Output Tokens"
                  }
                ],
                "fields": {}
              }
            }
          ],
          "type": "stat"
        },
        {
          "datasource": {
            "type": "tempo",
            "uid": "tempo"
          },
          "description": "Total input tokens across all LLM calls in time range",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": 0
                  },
                  {
                    "color": "yellow",
                    "value": 100000
                  },
                  {
                    "color": "red",
                    "value": 500000
                  }
                ]
              },
              "unit": "none"
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "Input Tokens"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "none"
                  },
                  {
                    "id": "decimals",
                    "value": 0
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 4,
            "w": 6,
            "x": 12,
            "y": 4
          },
          "id": 18,
          "options": {
            "colorMode": "value",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "auto",
            "percentChangeColorMode": "standard",
            "reduceOptions": {
              "calcs": [
                "sum"
              ],
              "fields": "/^Input Tokens$/",
              "values": false
            },
            "showPercentChange": false,
            "textMode": "auto",
            "wideLayout": true
          },
          "pluginVersion": "12.2.1",
          "targets": [
            {
              "datasource": {
                "type": "tempo",
                "uid": "tempo"
              },
              "limit": 100000,
              "metricsQueryType": "range",
              "query": "{resource.service.name=\"kagent\" && name=\"call_llm\" && span.gen_ai.request.model=~\"anthropic.*\"} | select(span.gen_ai.usage.input_tokens)",
              "queryType": "traceql",
              "refId": "A",
              "serviceMapUseNativeHistograms": false,
              "tableType": "spans"
            }
          ],
          "title": "Anthropic Input Tokens",
          "transformations": [
            {
              "id": "organize",
              "options": {
                "excludeByName": {
                  "durationMs": true,
                  "spanID": true,
                  "startTimeUnixNano": true,
                  "traceID": true
                },
                "indexByName": {},
                "renameByName": {
                  "gen_ai.usage.input_tokens": "Input Tokens"
                }
              }
            },
            {
              "id": "convertFieldType",
              "options": {
                "conversions": [
                  {
                    "destinationType": "number",
                    "targetField": "Input Tokens"
                  }
                ],
                "fields": {}
              }
            }
          ],
          "type": "stat"
        },
        {
          "datasource": {
            "type": "tempo",
            "uid": "tempo"
          },
          "description": "Total output tokens across all LLM calls in time range",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": 0
                  },
                  {
                    "color": "yellow",
                    "value": 50000
                  },
                  {
                    "color": "red",
                    "value": 200000
                  }
                ]
              },
              "unit": "none"
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "Output Tokens"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "none"
                  },
                  {
                    "id": "decimals",
                    "value": 0
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 4,
            "w": 6,
            "x": 18,
            "y": 4
          },
          "id": 16,
          "options": {
            "colorMode": "value",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "auto",
            "percentChangeColorMode": "standard",
            "reduceOptions": {
              "calcs": [
                "sum"
              ],
              "fields": "/^Output Tokens$/",
              "values": false
            },
            "showPercentChange": false,
            "textMode": "auto",
            "wideLayout": true
          },
          "pluginVersion": "12.2.1",
          "targets": [
            {
              "datasource": {
                "type": "tempo",
                "uid": "tempo"
              },
              "limit": 100000,
              "metricsQueryType": "range",
              "query": "{resource.service.name=\"kagent\" && name=\"call_llm\" && span.gen_ai.request.model=~\"anthropic.*\"} | select(span.gen_ai.usage.output_tokens)",
              "queryType": "traceql",
              "refId": "A",
              "serviceMapUseNativeHistograms": false,
              "tableType": "spans"
            }
          ],
          "title": "Anthropic Output Tokens",
          "transformations": [
            {
              "id": "organize",
              "options": {
                "excludeByName": {
                  "durationMs": true,
                  "spanID": true,
                  "startTimeUnixNano": true,
                  "traceID": true
                },
                "indexByName": {},
                "renameByName": {
                  "gen_ai.usage.output_tokens": "Output Tokens"
                }
              }
            },
            {
              "id": "convertFieldType",
              "options": {
                "conversions": [
                  {
                    "destinationType": "number",
                    "targetField": "Output Tokens"
                  }
                ],
                "fields": {}
              }
            }
          ],
          "type": "stat"
        },
        {
          "datasource": {
            "type": "tempo",
            "uid": "tempo"
          },
          "description": "GPT models: $0.03/1K input tokens, $0.06/1K output tokens",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": 0
                  },
                  {
                    "color": "yellow",
                    "value": 0.5
                  },
                  {
                    "color": "red",
                    "value": 5
                  }
                ]
              },
              "unit": "currencyUSD"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 4,
            "w": 6,
            "x": 0,
            "y": 8
          },
          "id": 10,
          "options": {
            "colorMode": "value",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "auto",
            "percentChangeColorMode": "standard",
            "reduceOptions": {
              "calcs": [
                "sum"
              ],
              "fields": "/^Cost$/",
              "values": false
            },
            "showPercentChange": false,
            "textMode": "auto",
            "wideLayout": true
          },
          "pluginVersion": "12.2.1",
          "targets": [
            {
              "datasource": {
                "type": "tempo",
                "uid": "tempo"
              },
              "limit": 100000,
              "metricsQueryType": "range",
              "query": "{resource.service.name=\"kagent\" && name=\"call_llm\" && span.gen_ai.request.model=~\"gpt.*\"} | select(span.gen_ai.usage.input_tokens, span.gen_ai.usage.output_tokens)",
              "queryType": "traceql",
              "refId": "A",
              "serviceMapUseNativeHistograms": false,
              "tableType": "spans"
            }
          ],
          "title": "GPT Cost ($0.03/$0.06 per 1K)",
          "transformations": [
            {
              "id": "organize",
              "options": {
                "excludeByName": {
                  "durationMs": true,
                  "spanID": true,
                  "startTimeUnixNano": true,
                  "traceID": true
                },
                "indexByName": {},
                "renameByName": {
                  "gen_ai.usage.input_tokens": "Input Tokens",
                  "gen_ai.usage.output_tokens": "Output Tokens"
                }
              }
            },
            {
              "id": "convertFieldType",
              "options": {
                "conversions": [
                  {
                    "destinationType": "number",
                    "targetField": "Input Tokens"
                  },
                  {
                    "destinationType": "number",
                    "targetField": "Output Tokens"
                  }
                ],
                "fields": {}
              }
            },
            {
              "id": "calculateField",
              "options": {
                "alias": "Input Cost",
                "binary": {
                  "left": "Input Tokens",
                  "operator": "*",
                  "right": "0.00003"
                },
                "mode": "binary"
              }
            },
            {
              "id": "calculateField",
              "options": {
                "alias": "Output Cost",
                "binary": {
                  "left": "Output Tokens",
                  "operator": "*",
                  "right": "0.00006"
                },
                "mode": "binary"
              }
            },
            {
              "id": "calculateField",
              "options": {
                "alias": "Cost",
                "binary": {
                  "left": "Input Cost",
                  "operator": "+",
                  "right": "Output Cost"
                },
                "mode": "binary"
              }
            }
          ],
          "type": "stat"
        },
        {
          "datasource": {
            "type": "tempo",
            "uid": "tempo"
          },
          "description": "Total number of calls to GPT models",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": 0
                  },
                  {
                    "color": "yellow",
                    "value": 50
                  },
                  {
                    "color": "red",
                    "value": 100
                  }
                ]
              },
              "unit": "none"
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "Model"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "none"
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 4,
            "w": 6,
            "x": 6,
            "y": 8
          },
          "id": 7,
          "options": {
            "colorMode": "value",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "auto",
            "percentChangeColorMode": "standard",
            "reduceOptions": {
              "calcs": [
                "count"
              ],
              "fields": "/^Model$/",
              "values": false
            },
            "showPercentChange": false,
            "textMode": "auto",
            "wideLayout": true
          },
          "pluginVersion": "12.2.1",
          "targets": [
            {
              "datasource": {
                "type": "tempo",
                "uid": "tempo"
              },
              "limit": 100000,
              "query": "{resource.service.name=\"kagent\" && name=\"call_llm\" && span.gen_ai.request.model=~\"gpt.*\"} | select(span.gen_ai.request.model)",
              "queryType": "traceql",
              "refId": "A",
              "tableType": "spans"
            }
          ],
          "title": "Total GPT Calls",
          "transformations": [
            {
              "id": "organize",
              "options": {
                "excludeByName": {
                  "durationMs": true,
                  "spanID": true,
                  "startTimeUnixNano": true,
                  "traceID": true
                },
                "indexByName": {},
                "renameByName": {
                  "gen_ai.request.model": "Model"
                }
              }
            }
          ],
          "type": "stat"
        },
        {
          "datasource": {
            "type": "tempo",
            "uid": "tempo"
          },
          "description": "Anthropic Claude: $0.015/1K input tokens, $0.075/1K output tokens",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": 0
                  },
                  {
                    "color": "yellow",
                    "value": 0.5
                  },
                  {
                    "color": "red",
                    "value": 5
                  }
                ]
              },
              "unit": "currencyUSD"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 4,
            "w": 6,
            "x": 12,
            "y": 8
          },
          "id": 14,
          "options": {
            "colorMode": "value",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "auto",
            "percentChangeColorMode": "standard",
            "reduceOptions": {
              "calcs": [
                "sum"
              ],
              "fields": "/^Cost$/",
              "values": false
            },
            "showPercentChange": false,
            "textMode": "auto",
            "wideLayout": true
          },
          "pluginVersion": "12.2.1",
          "targets": [
            {
              "datasource": {
                "type": "tempo",
                "uid": "tempo"
              },
              "limit": 100000,
              "metricsQueryType": "range",
              "query": "{resource.service.name=\"kagent\" && name=\"call_llm\" && span.gen_ai.request.model=~\"anthropic.*\"} | select(span.gen_ai.usage.input_tokens, span.gen_ai.usage.output_tokens)",
              "queryType": "traceql",
              "refId": "A",
              "serviceMapUseNativeHistograms": false,
              "tableType": "spans"
            }
          ],
          "title": "Anthropic Cost ($0.015/$0.075 per 1K)",
          "transformations": [
            {
              "id": "organize",
              "options": {
                "excludeByName": {
                  "durationMs": true,
                  "spanID": true,
                  "startTimeUnixNano": true,
                  "traceID": true
                },
                "indexByName": {},
                "renameByName": {
                  "gen_ai.usage.input_tokens": "Input Tokens",
                  "gen_ai.usage.output_tokens": "Output Tokens"
                }
              }
            },
            {
              "id": "convertFieldType",
              "options": {
                "conversions": [
                  {
                    "destinationType": "number",
                    "targetField": "Input Tokens"
                  },
                  {
                    "destinationType": "number",
                    "targetField": "Output Tokens"
                  }
                ],
                "fields": {}
              }
            },
            {
              "id": "calculateField",
              "options": {
                "alias": "Input Cost",
                "binary": {
                  "left": "Input Tokens",
                  "operator": "*",
                  "right": "0.000015"
                },
                "mode": "binary"
              }
            },
            {
              "id": "calculateField",
              "options": {
                "alias": "Output Cost",
                "binary": {
                  "left": "Output Tokens",
                  "operator": "*",
                  "right": "0.000075"
                },
                "mode": "binary"
              }
            },
            {
              "id": "calculateField",
              "options": {
                "alias": "Cost",
                "binary": {
                  "left": "Input Cost",
                  "operator": "+",
                  "right": "Output Cost"
                },
                "mode": "binary"
              }
            }
          ],
          "type": "stat"
        },
        {
          "datasource": {
            "type": "tempo",
            "uid": "tempo"
          },
          "description": "Total number of calls to Anthropic Claude models",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": 0
                  },
                  {
                    "color": "yellow",
                    "value": 50
                  },
                  {
                    "color": "red",
                    "value": 100
                  }
                ]
              },
              "unit": "none"
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "Model"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "none"
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 4,
            "w": 6,
            "x": 18,
            "y": 8
          },
          "id": 8,
          "options": {
            "colorMode": "value",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "auto",
            "percentChangeColorMode": "standard",
            "reduceOptions": {
              "calcs": [
                "count"
              ],
              "fields": "/^Model$/",
              "values": false
            },
            "showPercentChange": false,
            "textMode": "auto",
            "wideLayout": true
          },
          "pluginVersion": "12.2.1",
          "targets": [
            {
              "datasource": {
                "type": "tempo",
                "uid": "tempo"
              },
              "limit": 100000,
              "query": "{resource.service.name=\"kagent\" && name=\"call_llm\" && span.gen_ai.request.model=~\"anthropic.*\"} | select(span.gen_ai.request.model)",
              "queryType": "traceql",
              "refId": "A",
              "tableType": "spans"
            }
          ],
          "title": "Total Anthropic Calls",
          "transformations": [
            {
              "id": "organize",
              "options": {
                "excludeByName": {
                  "durationMs": true,
                  "spanID": true,
                  "startTimeUnixNano": true,
                  "traceID": true
                },
                "indexByName": {},
                "renameByName": {
                  "gen_ai.request.model": "Model"
                }
              }
            }
          ],
          "type": "stat"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "prometheus"
          },
          "description": "99th percentile latency for LLM calls",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": 0
                  },
                  {
                    "color": "yellow",
                    "value": 8000
                  },
                  {
                    "color": "red",
                    "value": 15000
                  }
                ]
              },
              "unit": "ms"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 4,
            "w": 12,
            "x": 0,
            "y": 12
          },
          "id": 12,
          "options": {
            "colorMode": "value",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "auto",
            "percentChangeColorMode": "standard",
            "reduceOptions": {
              "calcs": [
                "lastNotNull"
              ],
              "fields": "",
              "values": false
            },
            "showPercentChange": false,
            "textMode": "auto",
            "wideLayout": true
          },
          "pluginVersion": "12.2.1",
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "prometheus"
              },
              "expr": "histogram_quantile(0.99, sum by(le) (rate(otelcol_duration_milliseconds_bucket{service_name=\"kagent\",span_name=\"call_llm\"}[$__rate_interval])))",
              "refId": "A"
            }
          ],
          "title": "LLM Call Latency (P99)",
          "type": "stat"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "prometheus"
          },
          "description": "Average duration of LLM calls",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": 0
                  },
                  {
                    "color": "yellow",
                    "value": 3000
                  },
                  {
                    "color": "red",
                    "value": 7000
                  }
                ]
              },
              "unit": "ms"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 4,
            "w": 12,
            "x": 12,
            "y": 12
          },
          "id": 13,
          "options": {
            "colorMode": "value",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "auto",
            "percentChangeColorMode": "standard",
            "reduceOptions": {
              "calcs": [
                "lastNotNull"
              ],
              "fields": "",
              "values": false
            },
            "showPercentChange": false,
            "textMode": "auto",
            "wideLayout": true
          },
          "pluginVersion": "12.2.1",
          "targets": [
            {
              "datasource": {
                "type": "prometheus",
                "uid": "prometheus"
              },
              "expr": "sum(rate(otelcol_duration_milliseconds_sum{service_name=\"kagent\",span_name=\"call_llm\"}[$__rate_interval])) / sum(rate(otelcol_duration_milliseconds_count{service_name=\"kagent\",span_name=\"call_llm\"}[$__rate_interval]))",
              "refId": "A"
            }
          ],
          "title": "Avg LLM Call Duration",
          "type": "stat"
        },
        {
          "datasource": {
            "type": "tempo",
            "uid": "tempo"
          },
          "description": "Recent kagent requests. Click trace ID to view details. POST / traces contain LLM calls with token information.",
          "fieldConfig": {
            "defaults": {
              "custom": {
                "align": "left",
                "cellOptions": {
                  "type": "auto"
                },
                "footer": {
                  "reducers": []
                },
                "inspect": false
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": 0
                  }
                ]
              }
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "Trace ID"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 280
                  },
                  {
                    "id": "links",
                    "value": [
                      {
                        "title": "View in Explore",
                        "url": "/explore?left={%22datasource%22:%22tempo%22,%22queries%22:[{%22queryType%22:%22traceqlSearch%22,%22query%22:%22${__data.fields[%22Trace%20ID%22]}%22}],%22range%22:{%22from%22:%22now-6h%22,%22to%22:%22now%22}}"
                      }
                    ]
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "Duration"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "ms"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byRegexp",
                  "options": ".*[Tt]okens.*"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "none"
                  },
                  {
                    "id": "decimals",
                    "value": 0
                  },
                  {
                    "id": "custom.cellOptions",
                    "value": {
                      "type": "color-text"
                    }
                  },
                  {
                    "id": "color",
                    "value": {
                      "mode": "continuous-GrYlRd"
                    }
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "User"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 158
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "Total Tokens"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 110
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "Output Tokens"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 121
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "Input Tokens"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 113
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "Model"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 275
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 12,
            "w": 24,
            "x": 0,
            "y": 16
          },
          "id": 1,
          "options": {
            "cellHeight": "sm",
            "showHeader": true,
            "sortBy": [
              {
                "desc": true,
                "displayName": "Start time"
              }
            ]
          },
          "pluginVersion": "12.2.1",
          "targets": [
            {
              "datasource": {
                "type": "tempo",
                "uid": "tempo"
              },
              "limit": 50,
              "query": "{resource.service.name=\"kagent\" && name=\"call_llm\"} | select(span.gen_ai.usage.input_tokens, span.gen_ai.usage.output_tokens, span.gen_ai.request.model, span.gen_ai.conversation.id, span.gen_ai.operation.name, span.kagent.user_id, span.gen_ai.agent.name)",
              "queryType": "traceql",
              "refId": "A",
              "tableType": "spans"
            }
          ],
          "title": "Recent LLM Calls with Token Usage",
          "transformations": [
            {
              "id": "convertFieldType",
              "options": {
                "conversions": [
                  {
                    "destinationType": "number",
                    "targetField": "gen_ai.usage.input_tokens"
                  },
                  {
                    "destinationType": "number",
                    "targetField": "gen_ai.usage.output_tokens"
                  }
                ],
                "fields": {}
              }
            },
            {
              "id": "calculateField",
              "options": {
                "alias": "Total Tokens",
                "binary": {
                  "left": "gen_ai.usage.input_tokens",
                  "operator": "+",
                  "right": "gen_ai.usage.output_tokens"
                },
                "mode": "binary"
              }
            },
            {
              "id": "organize",
              "options": {
                "excludeByName": {
                  "gcp.vertex.agent.event_id": true,
                  "gcp.vertex.agent.invocation_id": true,
                  "gcp.vertex.agent.llm_request": true,
                  "gcp.vertex.agent.llm_response": true,
                  "gcp.vertex.agent.session_id": true,
                  "spanID": true
                },
                "indexByName": {
                  "Total Tokens": 7,
                  "durationMs": 9,
                  "gen_ai.agent.name": 2,
                  "gen_ai.conversation.id": 8,
                  "gen_ai.operation.name": 3,
                  "gen_ai.request.model": 4,
                  "gen_ai.usage.input_tokens": 5,
                  "gen_ai.usage.output_tokens": 6,
                  "kagent.user_id": 10,
                  "startTimeUnixNano": 1,
                  "traceID": 0
                },
                "renameByName": {
                  "durationMs": "Duration (ms)",
                  "gen_ai.agent.name": "Agent",
                  "gen_ai.conversation.id": "Conversation",
                  "gen_ai.operation.name": "Operation",
                  "gen_ai.request.model": "Model",
                  "gen_ai.usage.input_tokens": "Input Tokens",
                  "gen_ai.usage.output_tokens": "Output Tokens",
                  "kagent.user_id": "User",
                  "startTimeUnixNano": "Time",
                  "traceID": "Trace ID"
                }
              }
            }
          ],
          "type": "table"
        },
        {
          "datasource": {
            "type": "tempo",
            "uid": "tempo"
          },
          "description": "Recent agent invocations showing which agents are being called",
          "fieldConfig": {
            "defaults": {
              "custom": {
                "align": "left",
                "cellOptions": {
                  "type": "auto"
                },
                "footer": {
                  "reducers": []
                },
                "inspect": false
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": 0
                  }
                ]
              }
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "Trace ID"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 280
                  },
                  {
                    "id": "links",
                    "value": [
                      {
                        "title": "View in Explore",
                        "url": "/explore?left={%22datasource%22:%22tempo%22,%22queries%22:[{%22queryType%22:%22traceqlSearch%22,%22query%22:%22${__data.fields[%22Trace%20ID%22]}%22}],%22range%22:{%22from%22:%22now-6h%22,%22to%22:%22now%22}}"
                      }
                    ]
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "Duration"
                },
                "properties": [
                  {
                    "id": "unit",
                    "value": "ms"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "Agent"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 215
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "Trace Service"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 96
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "Trace Name"
                },
                "properties": [
                  {
                    "id": "custom.width",
                    "value": 89
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 8,
            "w": 24,
            "x": 0,
            "y": 28
          },
          "id": 9,
          "options": {
            "cellHeight": "sm",
            "showHeader": true,
            "sortBy": [
              {
                "desc": true,
                "displayName": "Start Time"
              }
            ]
          },
          "pluginVersion": "12.2.1",
          "targets": [
            {
              "datasource": {
                "type": "tempo",
                "uid": "tempo"
              },
              "limit": 50,
              "query": "{resource.service.name=\"kagent\" && name=~\"invoke_agent.*\"} | select(span.gen_ai.agent.name, span.gen_ai.conversation.id, span.gen_ai.operation.name, span.kagent.user_id)",
              "queryType": "traceql",
              "refId": "A",
              "tableType": "spans"
            }
          ],
          "title": "Recent Agent Invocations",
          "transformations": [
            {
              "id": "organize",
              "options": {
                "excludeByName": {
                  "spanID": true
                },
                "indexByName": {
                  "durationMs": 5,
                  "gen_ai.agent.name": 2,
                  "gen_ai.conversation.id": 4,
                  "gen_ai.operation.name": 3,
                  "kagent.user_id": 6,
                  "startTimeUnixNano": 1,
                  "traceID": 0
                },
                "renameByName": {
                  "durationMs": "Duration (ms)",
                  "gen_ai.agent.name": "Agent",
                  "gen_ai.conversation.id": "Conversation",
                  "gen_ai.operation.name": "Operation",
                  "kagent.user_id": "User",
                  "startTimeUnixNano": "Time",
                  "traceID": "Trace ID"
                }
              }
            }
          ],
          "type": "table"
        }
      ],
      "preload": false,
      "refresh": "30s",
      "schemaVersion": 42,
      "tags": [
        "kagent",
        "LLM",
        "tokens",
        "usage"
      ],
      "templating": {
        "list": []
      },
      "time": {
        "from": "now-6h",
        "to": "now"
      },
      "timepicker": {},
      "timezone": "America/Denver",
      "title": "kagent - LLM Token Usage",
      "uid": "kagent-llm-usage",
      "version": 45
    }